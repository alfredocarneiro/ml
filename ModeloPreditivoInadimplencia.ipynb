{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudo do projeto ModeloPreditivoInadimplencia\n",
    "\n",
    "Estudo baseado no projeto do canal https://www.youtube.com/@nerddosdados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação \n",
    "\n",
    "Preparando os pacotes que irão ser utilizados e carregando os dados do banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação dos Pacotes\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import joblib # Utilizado para salvar o modelo preditivo\n",
    "from sklearn.preprocessing import LabelEncoder #Utilizada para fazer o OneHotEncoding\n",
    "from sklearn.metrics import mean_squared_error,precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn import under_sampling, over_sampling #Utilizada para fazer o balanceamento de dados\n",
    "from imblearn.over_sampling import SMOTE #Utilizada para fazer o balanceamento de dados\n",
    "from sklearn.preprocessing import MinMaxScaler #Utilizada para fazer a padronização dos dados\n",
    "from sklearn.metrics import r2_score # Utilizado para medir a acuracia do modelo preditivo\n",
    "import pymssql as sql #conexão SQL\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação dos arquivos direto do banco de dados MSSQL\n",
    "\n",
    "# Cria a conexão com o SQL Server passando os parametros (Servidor, Usuário, Senha, Database)\n",
    "conexao = sql.connect('localhost', 'usuario_python', '123456', 'MODELOS_PREDITIVOS')\n",
    "\n",
    "# Chama a consulta ao banco de dados passando os parametros da conexão criada\n",
    "df_original = pd.read_sql_query('select * from EXTRACAO_DADOS_SISTEMA', conexao)\n",
    "\n",
    "# Fecha conexão com banco de dados\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamanho do conjunto de dados. \n",
    "df_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visão geral do conjunto de dados\n",
    "df_original.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando os dados missing podemos constatar o seguinte:\n",
    "# Variavel DATA_ASSINATURA_CONTRATO possui 1 registro faltando\n",
    "# Variavel VL_TOTAL_PC_PAGAS possui 4 registros faltando\n",
    "\n",
    "# Como temos um total de 10.415 observações então excluir 5 observações NÃO afetará nosso trabalho\n",
    "\n",
    "df_original.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Informações básicas sobre tipos de variáveis\n",
    "df_original.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o período dos dados coletados\n",
    "inicio = pd.to_datetime(df_original['DATA_ASSINATURA_CONTRATO']).dt.date.min()\n",
    "fim = pd.to_datetime(df_original['DATA_ASSINATURA_CONTRATO']).dt.date.max()\n",
    "print('Período dos dados - De:', inicio, 'Até:',fim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de valores únicos de cada variável\n",
    "# A variável TIPO_FINANCIAMENTO possui valor unico, então será retirada do nosso DataFrame\n",
    "\n",
    "valores_unicos = []\n",
    "for i in df_original.columns[0:20].tolist():\n",
    "    print(i, ':', len(df_original[i].astype(str).value_counts()))\n",
    "    valores_unicos.append(len(df_original[i].astype(str).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando algumas medidas estatisticas\n",
    "df_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maior Valor Financiado:', df_original['VALOR_FINANCIAMENTO'].max())\n",
    "print('Menor Valor Financiado:', df_original['VALOR_FINANCIAMENTO'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variavel alvo precisará ser balanceada na etapa de pré-processamento\n",
    "df_original.groupby(['INADIMPLENTE_COBRANCA']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui não precisaremos alterar nada\n",
    "df_original.groupby(['PZ_FINANCIAMENTO']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui não precisaremos fazer nenhum tratamento\n",
    "df_original.groupby(['RENDA_MENSAL_CLIENTE']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe que temos uma variedade muito grande de valor financiado, neste caso devemos criar um range de valores\n",
    "df_original.groupby(['VALOR_FINANCIAMENTO']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo os registros NA (5 registros)\n",
    "df_original.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando faixa de prazos para utilizarmos no modelo preditivo\n",
    "bins = [-100, 120, 180, 240]\n",
    "labels = ['Até 120 Meses', '121 até 180 Meses', '181 até 240 Meses']\n",
    "df_original['FAIXA_PRAZO_FINANCIAMENTO'] = pd.cut(df_original['PZ_FINANCIAMENTO'], bins=bins, labels=labels)\n",
    "pd.value_counts(df_original.FAIXA_PRAZO_FINANCIAMENTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando faixa salarial para utilizarmos no modelo preditivo\n",
    "bins = [-100, 100000, 200000, 300000, 400000, 500000, 750000, 1000000, 9000000000]\n",
    "labels = ['Até 100 mil', '101 até 200 mil', '201 até 300 mil', '301 até 400 mil', '401 até 500 mil', \n",
    "          '501 até 750 mil', 'De 751 até 1.000.000','Mais de 1.000.000']\n",
    "df_original['FAIXA_VALOR_FINANCIADO'] = pd.cut(df_original['VALOR_FINANCIAMENTO'], bins=bins, labels=labels)\n",
    "pd.value_counts(df_original.FAIXA_VALOR_FINANCIADO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos retirar a variável TIPO FINANCIAMENTO como vimos anteriormente\n",
    "# Devemos retirar a variável VALOR_FINANCIAMENTO pois criamos uma variavel de faixa de valores para ela.\n",
    "# Devemos retirar a variável PRAZO_FINANCIAMENTO pois criamos uma variavel de faixa de meses para ela.\n",
    "# Podemos retirar a variável DATA_ASSINATURA_CONTRATO\n",
    "# Podemos retirar a variável NUMERO_CONTRATO\n",
    "\n",
    "colunas = ['TAXA_AO_ANO', 'CIDADE_CLIENTE', 'ESTADO_CLIENTE','RENDA_MENSAL_CLIENTE', \n",
    "           'QT_PC_ATRASO', 'QT_DIAS_PRIM_PC_ATRASO','QT_TOTAL_PC_PAGAS',\n",
    "           'VL_TOTAL_PC_PAGAS', 'QT_PC_PAGA_EM_DIA','QT_DIAS_MIN_ATRASO',\n",
    "           'QT_DIAS_MAX_ATRASO', 'QT_DIAS_MEDIA_ATRASO','VALOR_PARCELA',\n",
    "           'IDADE_DATA_ASSINATURA_CONTRATO', 'FAIXA_VALOR_FINANCIADO',\n",
    "           'FAIXA_PRAZO_FINANCIAMENTO','INADIMPLENTE_COBRANCA']\n",
    "\n",
    "df_dados = pd.DataFrame(df_original, columns=colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise exploratória \n",
    "\n",
    "Nesta analise temos 2 objetivos: a variável alvo (INADIMPLENTE_COBRANCA), avaliar as variáveis categóricas para conhecimento dos dados e descartar variáveis que não fazem sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisando como a variavel alvo está distribuida.\n",
    "#Aqui podemos observar que há muito mais cotas como INADIMPLENTE\n",
    "#dessa forma, precisaremos balancear o dataset mais adiante.\n",
    "df_dados.INADIMPLENTE_COBRANCA.value_counts().plot(kind='bar', title='Inadimplentes',color = ['#1F77B4', '#FF7F0E']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos constatar na analise que não há discrepancias nestas variaveis\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [14.00, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "sns.countplot(data = df_dados, x = \"FAIXA_VALOR_FINANCIADO\", hue = \"INADIMPLENTE_COBRANCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos constatar na analise que não há discrepancias nestas variaveis\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [12.00, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "sns.countplot(data = df_dados, x = \"FAIXA_PRAZO_FINANCIAMENTO\", hue = \"INADIMPLENTE_COBRANCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise de Variaveis numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregar variaveis para plot\n",
    "variaveis_numericas = []\n",
    "for i in df_dados.columns[0:17].tolist():\n",
    "        if df_dados.dtypes[i] == 'int64' or df_dados.dtypes[i] == 'float64':                        \n",
    "            variaveis_numericas.append(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando as variáveis numéricas\n",
    "variaveis_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantidade de variaveis\n",
    "len(variaveis_numericas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos observar nos boxplots abaixo que as variáveis númericas apresentam uma grande quantidade de \"possíveis\" outliers\n",
    "#Precisamos avaliar cada uma dessas variaveis dentro do contexto dos dados para saber se realmente iremos trata-las como outlier\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [14.00, 14.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(4, 3) #4 linhas e 3 colunas\n",
    "\n",
    "linha = 0\n",
    "coluna = 0\n",
    "for i in variaveis_numericas:\n",
    "    sns.boxplot(data = df_dados, y=i, ax=axes[linha][coluna])\n",
    "    coluna += 1\n",
    "    if coluna == 3:\n",
    "        linha += 1\n",
    "        coluna = 0            \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar variaveis categoricas para OneHotEncoding, ou seja transformar os campos categoricos em valores inteiros\n",
    "# Colocamos o SLICE até 16 porque NÃO precisamos fazer OneHotEncoding para variavel TARGET\n",
    "variaveis_categoricas = []\n",
    "for i in df_dados.columns[0:16].tolist():\n",
    "        if df_dados.dtypes[i] == 'object' or df_dados.dtypes[i] == 'category':                        \n",
    "            variaveis_categoricas.append(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as variaveis categoricas\n",
    "variaveis_categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o encoder e aplica OneHotEncoder\n",
    "lb = LabelEncoder()\n",
    "\n",
    "for var in variaveis_categoricas:\n",
    "    df_dados[var] = lb.fit_transform(df_dados[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os tipos das variaveis\n",
    "df_dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiznado a quantidade da variavel target para balanceamento\n",
    "variavel_target = df_dados.INADIMPLENTE_COBRANCA.value_counts()\n",
    "variavel_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar variaveis preditoras e target\n",
    "PREDITORAS = df_dados.iloc[:, 0:15]  \n",
    "TARGET = df_dados.iloc[:, 16] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as variaveis preditoras\n",
    "PREDITORAS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a variavel target\n",
    "TARGET.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed para reproduzir o mesmo resultado\n",
    "seed = 100\n",
    "\n",
    "# Cria o balanceador SMOTE\n",
    "balanceador = SMOTE(random_state = seed)\n",
    "\n",
    "# Aplica o balanceador\n",
    "PREDITORAS_RES, TARGET_RES = balanceador.fit_resample(PREDITORAS, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o balanceamento da variável TARGET\n",
    "plt.rcParams[\"figure.figsize\"] = [12.00, 5.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "TARGET_RES.value_counts().plot(kind='bar', title='Inadimplentes x Não Inadimplentes',color = ['#1F77B4', '#FF7F0E']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de registros antes do balanceamento\n",
    "PREDITORAS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de registros antes do balanceamento\n",
    "TARGET.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de registros após do balanceamento\n",
    "PREDITORAS_RES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de registros após do balanceamento\n",
    "TARGET_RES.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação e normalização dos dados / Criação e treino do modelo / Avaliação de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão em Dados de Treino e Teste.\n",
    "X_treino, X_teste, Y_treino, Y_teste = train_test_split(PREDITORAS_RES, TARGET_RES, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando as Variáveis - Pré Processamento dos Dados\n",
    "Normalizador = MinMaxScaler()\n",
    "X_treino_normalizados = Normalizador.fit_transform(X_treino)\n",
    "X_teste_normalizados = Normalizador.transform(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando a dimensão dos dados de treino\n",
    "X_treino_normalizados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando os dados de treino normalizados\n",
    "X_treino_normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o classificador com Random Forest\n",
    "clf = RandomForestClassifier(n_estimators  = 300)\n",
    "\n",
    "# Construção do modelo\n",
    "clf = clf.fit(X_treino_normalizados, Y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a acuracia do modelo com dados de teste\n",
    "scores = clf.score(X_teste_normalizados,Y_teste)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo a importancia de cada variavel no modelo preditivo\n",
    "plt.rcParams[\"figure.figsize\"] = [10.00, 10.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "importances = pd.Series(data=clf.feature_importances_, index=PREDITORAS.columns)\n",
    "importances = importances.sort_values(ascending = False)\n",
    "sns.barplot(x=importances, y=importances.index, orient='h').set_title('Importância de cada variável')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo criado e treinado\n",
    "joblib.dump(clf, 'modelo_treinado.pk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação para produção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo treinado\n",
    "clf = joblib.load('modelo_treinado.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação do arquivo de dados\n",
    "\n",
    "# Cria a conexão com o SQL Server passando os parametros (Servidor, Usuário, Senha, Database)\n",
    "conexao = sql.connect('localhost', 'usuario_python', '123456', 'MODELOS_PREDITIVOS')\n",
    "\n",
    "# Chama a consulta ao banco de dados passando os parametros da conexão criada\n",
    "df_original = pd.read_sql_query('select * from EXTRACAO_DADOS_SISTEMA', conexao)\n",
    "\n",
    "# Fecha conexão com banco de dados\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo dados missing\n",
    "df_original.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Criando faixa de prazos para utilizarmos no modelo preditivo\n",
    "bins = [-100, 120, 180, 240]\n",
    "labels = ['Até 120 Meses', '121 até 180 Meses', '181 até 240 Meses']\n",
    "df_original['FAIXA_PRAZO_FINANCIAMENTO'] = pd.cut(df_original['PZ_FINANCIAMENTO'], bins=bins, labels=labels)\n",
    "pd.value_counts(df_original.FAIXA_PRAZO_FINANCIAMENTO)\n",
    "\n",
    "\n",
    "# Criando faixa salarial para utilizarmos no modelo preditivo\n",
    "bins = [-100, 100000, 200000, 300000, 400000, 500000, 750000, 1000000, 9000000000]\n",
    "labels = ['Até 100 mil', '101 até 200 mil', '201 até 300 mil', '301 até 400 mil', '401 até 500 mil', \n",
    "          '501 até 750 mil', 'De 751 até 1.000.000','Mais de 1.000.000']\n",
    "df_original['FAIXA_VALOR_FINANCIADO'] = pd.cut(df_original['VALOR_FINANCIAMENTO'], bins=bins, labels=labels)\n",
    "pd.value_counts(df_original.FAIXA_VALOR_FINANCIADO)\n",
    "\n",
    "columns = ['TAXA_AO_ANO', 'CIDADE_CLIENTE', 'ESTADO_CLIENTE','RENDA_MENSAL_CLIENTE', \n",
    "           'QT_PC_ATRASO', 'QT_DIAS_PRIM_PC_ATRASO','QT_TOTAL_PC_PAGAS',\n",
    "           'VL_TOTAL_PC_PAGAS', 'QT_PC_PAGA_EM_DIA','QT_DIAS_MIN_ATRASO',\n",
    "           'QT_DIAS_MAX_ATRASO', 'QT_DIAS_MEDIA_ATRASO','VALOR_PARCELA',\n",
    "           'IDADE_DATA_ASSINATURA_CONTRATO', 'FAIXA_VALOR_FINANCIADO',\n",
    "           'FAIXA_PRAZO_FINANCIAMENTO','INADIMPLENTE_COBRANCA',]\n",
    "\n",
    "df_dados = pd.DataFrame(df_original, columns=columns)\n",
    "\n",
    "# carregar variaveis categoricas para OneHotEncoding\n",
    "variaveis_categoricas = []\n",
    "for i in df_dados.columns[0:16].tolist():\n",
    "        if df_dados.dtypes[i] == 'object' or df_dados.dtypes[i] == 'category':                        \n",
    "            variaveis_categoricas.append(i) \n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "for var in variaveis_categoricas:\n",
    "    df_dados[var] = lb.fit_transform(df_dados[var])\n",
    "\n",
    "\n",
    "\n",
    "# Separar variaveis preditoras\n",
    "PREDITORAS = df_dados.iloc[:, 0:15]          \n",
    "    \n",
    "\n",
    "# Fazendo a normalização dos dados    \n",
    "Normalizador = MinMaxScaler()\n",
    "dados_normalizados = Normalizador.fit_transform(PREDITORAS)\n",
    "\n",
    "previsoes = clf.predict(dados_normalizados)\n",
    "probabilidades = clf.predict_proba(dados_normalizados)\n",
    "df_original['PREVISOES'] = previsoes\n",
    "df_original['PROBABILIDADES'] = probabilidades[:, 1]\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.to_excel('df_original_com_probabilidades.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando nova tabela e inserindo os dados de predição no sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as colunas que serão utilizadas para inserção\n",
    "columns = ['NUMERO_CONTRATO', 'PREVISOES', 'PROBABILIDADES']\n",
    "df_conversao = pd.DataFrame(df_original, columns=columns)\n",
    "df_conversao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql as sql\n",
    "# Cria a conexão com o SQL Server passando os parametros (Servidor, Usuário, Senha, Database)\n",
    "conexao = sql.connect('localhost', 'usuario_python', '123456', 'MODELOS_PREDITIVOS')\n",
    "\n",
    "# Criando um cursor e executando um LOOP no DataFrame para fazer o INSERT no banco SQL Server\n",
    "\n",
    "cursor = conexao.cursor()\n",
    "\n",
    "for index,row in df_conversao.iterrows():\n",
    "    sql = \"INSERT INTO RESULTADOS_INTERMEDIARIO (NUMERO_CONTRATO, PREVISOES, PROBABILIDADES) VALUES (%s, %s, %s)\"\n",
    "    val = (row['NUMERO_CONTRATO'],row['PREVISOES'],row['PROBABILIDADES'])    \n",
    "    cursor.execute(sql, val)\n",
    "    conexao.commit()\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Dados inseridos com sucesso no SQL\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql as sql\n",
    "conexao = sql.connect('localhost', 'usuario_python', '123456', 'MODELOS_PREDITIVOS')\n",
    "cursor = conexao.cursor()\n",
    "cursor.execute('EXEC SP_INPUT_RESULTADOS_MODELO_PREDITIVO')    \n",
    "conexao.commit()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql as sql\n",
    "conexao = sql.connect('localhost', 'usuario_python', '123456', 'MODELOS_PREDITIVOS')\n",
    "cursor = conexao.cursor()\n",
    "cursor.execute('TRUNCATE TABLE RESULTADOS_INTERMEDIARIO')\n",
    "conexao.commit()\n",
    "conexao.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
